defaults:
  - defaults
  - _self_

config_name_or_path: ./model_configs/meta-llama/Llama-3.1-8B

config_kwargs:
  attn_input_format: "bshd"
  self_attn_mask_type: "causal"

cp_size: 1

use_mock_dataset: true
use_sequence_packing: false
use_meta_device: true
use_torch_compile: false

num_train_steps: 100

dataset:
  tokenizer_name_or_path: null  # Not needed for mock dataset
  micro_batch_size: 1
  max_seq_length: 8192
  num_samples: 100_000
  load_dataset_kwargs: null  # Not needed for mock dataset

wandb:
  name: "llama3-cp-benchmark"
  mode: "offline"

lr_scheduler_kwargs:
  num_warmup_steps: 10
  num_decay_steps: 90

checkpoint:
  ckpt_dir: null
  save_final_model: false
  resume_from_checkpoint: false

logger:
  frequency: 1
